import os
import asyncio
import requests
import json
import numpy as np
import sounddevice as sd
import whisper
import time
import webrtcvad
from google import genai 
from google.genai.types import Content, Part
from dotenv import load_dotenv
import urllib.parse
import wavio # éŒ²éŸ³ä¿å­˜ç”¨


# --- ç’°å¢ƒè¨­å®š ---
load_dotenv()
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

# --- ã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®š ---
VOICEVOX_ENGINE_URL = "http://127.0.0.1:50021" 
VOICEVOX_SPEAKER_ID = 14  
RATE = 48000 
VOICEVOX_SPEED_SCALE = 1.13 # 1.0ãŒæ¨™æº–é€Ÿåº¦ã€‚1.2ã€œ1.5ç¨‹åº¦ãŒè‡ªç„¶
#VOICEVOX_PITCH_SCALE = 1.0 #
CHANNELS = 1
SILENCE_TIMEOUT_SECONDS = 1.5 # VADã®ç„¡éŸ³æ¤œå‡ºã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
FRAME_DURATION_MS = 30 # å‡¦ç†ã™ã‚‹éŸ³å£°ãƒ•ãƒ¬ãƒ¼ãƒ ã®é•·ã• (VADè¨­å®š)
FRAME_SIZE = int(RATE * FRAME_DURATION_MS / 1000) 
VAD_AGGRESSIVENESS = 3 # VADã®ç©æ¥µæ€§
WHISPER_MODEL_NAME = "small" # ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«å
WHISPER_MODEL = None        # ãƒ¢ãƒ‡ãƒ«æ ¼ç´ç”¨å¤‰æ•°
# --- çµ‚äº†ã‚³ãƒãƒ³ãƒ‰è¨­å®š ---
EXIT_COMMANDS = ["ã•ã‚ˆã†ãªã‚‰", "ã•ã‚ˆãªã‚‰"]

# --- ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ– ---
gemini_client = genai.Client(api_key=GEMINI_API_KEY)
WHISPER_MODEL = None 

async def async_generator_from_string(text):
    """ã‚·ãƒ³ãƒ—ãƒ«ãªæ–‡å­—åˆ—ã‚’éåŒæœŸã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ã¨ã—ã¦è¿”ã™"""
    yield text

# ====================================================================
# I. éŸ³å£°å…¥åŠ› (VAD & ãƒ­ãƒ¼ã‚«ãƒ«Whisper)
# ====================================================================

def setup_whisper_model():
    """Whisperãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã€ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã«è¨­å®šã™ã‚‹"""
    global WHISPER_MODEL
    if WHISPER_MODEL is None:
        print(f"ğŸ‘‚ Whisper: ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ« '{WHISPER_MODEL_NAME}' ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")
        try:
            import torch
            device_to_use = "cuda" if torch.cuda.is_available() else "cpu"
            print(f"ğŸ‘‚ Whisper: æ¤œå‡ºã•ã‚ŒãŸãƒ‡ãƒã‚¤ã‚¹: {device_to_use}")

            WHISPER_MODEL = whisper.load_model(WHISPER_MODEL_NAME, device=device_to_use)
        except Exception as e:
            print(f"âŒ Whisperãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
            return False
        print("âœ… Whisper: ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å®Œäº†ã€‚")
    return True

async def record_and_transcribe():
    """VADã§éŒ²éŸ³ã—ã€ãƒ­ãƒ¼ã‚«ãƒ«Whisperã§è»¢å†™ã™ã‚‹"""
    print("\nğŸ¤ éŒ²éŸ³å¾…æ©Ÿä¸­... è©±ã—å§‹ã‚ã¦ãã ã•ã„ã€‚")
    vad = webrtcvad.Vad(VAD_AGGRESSIVENESS)
    stream = sd.InputStream(samplerate=RATE, channels=CHANNELS, dtype='int16')
    stream.start()
    
    recorded_frames = []
    speaking_start_time = None
    silence_frame_count = 0
    
    # === VADã«ã‚ˆã‚‹è‡ªå‹•éŒ²éŸ³ãƒ«ãƒ¼ãƒ— ===
    while True:
        # NOTE: sd.InputStream.read() ã¯ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°é–¢æ•°ã ãŒã€ã“ã®ã‚¿ã‚¹ã‚¯ã¯IOå¾…ã¡ã®ãŸã‚å•é¡Œãªã„
        audio_frame, overflowed = stream.read(FRAME_SIZE)
        is_speech = vad.is_speech(audio_frame.tobytes(), RATE)
        
        if is_speech:
            if speaking_start_time is None:
                speaking_start_time = time.time()
                print("ğŸ—£ï¸ ç™ºè©±é–‹å§‹ã‚’æ¤œå‡ºã€‚")
            
            silence_frame_count = 0
            recorded_frames.append(audio_frame.flatten())
        else:
            if speaking_start_time is not None:
                silence_frame_count += 1
                recorded_frames.append(audio_frame.flatten()) 
                
                if silence_frame_count * FRAME_DURATION_MS / 1000 > SILENCE_TIMEOUT_SECONDS:
                    print(f"ğŸ¤« {SILENCE_TIMEOUT_SECONDS}ç§’é–“ã®ç„¡éŸ³ã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚")
                    break 
            
        if speaking_start_time is not None and time.time() - speaking_start_time > 30:
            print("ğŸ•’ æœ€å¤§éŒ²éŸ³æ™‚é–“ï¼ˆ30ç§’ï¼‰ã‚’è¶…éã—ã¾ã—ãŸã€‚")
            break

    stream.stop()
    stream.close()
    
    if not recorded_frames:
        print("ğŸ¤·â€â™‚ï¸ ç™ºè©±ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
        return None
    
    recording = np.concatenate(recorded_frames, axis=0)
    print(f"âœ… éŒ²éŸ³çµ‚äº†ã€‚åˆè¨ˆéŒ²éŸ³æ™‚é–“: {len(recording) / RATE:.2f}ç§’")
    
    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
    temp_wav_path = "temp_input.wav"
    wavio.write(temp_wav_path, recording, RATE, sampwidth=2)

    # === Whisperã«ã‚ˆã‚‹è»¢å†™ ===
    print("ğŸ‘‚ Whisper: è»¢å†™å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™...")
    try:
        # è»¢å†™å‡¦ç†ã¯éåŒæœŸã‚¹ãƒ¬ãƒƒãƒ‰ã§å®Ÿè¡Œ
        result = await asyncio.to_thread(
            WHISPER_MODEL.transcribe, temp_wav_path, language="ja"
        )
        os.remove(temp_wav_path) # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        transcript = result["text"].strip()
        print(f"âœ… Whisper: å®Œäº†ã€‚ãƒ†ã‚­ã‚¹ãƒˆ: \"{transcript}\"")
        return transcript
    except Exception as e:
        print(f"âŒ Whisperè»¢å†™ã‚¨ãƒ©ãƒ¼: {e}")
        os.remove(temp_wav_path)
        return None

# ====================================================================
# II. å¿œç­”ç”Ÿæˆ (Gemini: ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°) - å±¥æ­´ç®¡ç†æ©Ÿèƒ½ã‚’è¿½åŠ 
# ====================================================================

async def generate_gemini_stream(prompt_text, conversation_history):
    """Gemini APIã‚’ä½¿ç”¨ã—ã¦å¿œç­”ã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§ç”Ÿæˆã™ã‚‹"""
    print("ğŸ¤– Gemini: å¿œç­”ç”Ÿæˆã‚’é–‹å§‹ã—ã¾ã™...")
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­å®š
    system_instruction = "ã‚ãªãŸã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä½œæ¥­ä¸­ã®è©±ã—ç›¸æ‰‹ã¨ãªã‚‹ã€çŸ¥è­˜ãŒè±Šå¯Œã§å—å‹•çš„ãªå¥³æ€§ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®ã€Œã“ã‚ˆã¿ã€ã§ã™ã€‚è³ªå•ã«ã¯ç°¡æ½”ã«ã€è¦ªã—ã¿ã‚„ã™ã„ãƒˆãƒ¼ãƒ³ã§ç­”ãˆã¦ãã ã•ã„ã€‚ã‚†ã£ãŸã‚Šã—ãŸè©±ã—æ–¹ã§ã€ãŸã‚å£ã§ã®ä¼šè©±ã‚’ã—ã¦ãã ã•ã„ã€‚å¿œç­”ã«ç‰¹æ®Šæ–‡å­—ã‚„çµµæ–‡å­—ã‚’å«ã‚ãªã„ã§ãã ã•ã„ã€‚ç®‡æ¡æ›¸ãã§ã®å›ç­”ã‚’æ§ãˆã¦ãã ã•ã„ã€‚äº‹å®Ÿã®å›ç­”ã‚’é™¤ã„ã¦æ–­è¨€ã‚’æ§ãˆã¦ãã ã•ã„ã€‚AIå´ã‹ã‚‰ç©æ¥µçš„ã«è©±é¡Œã‚’æŒ¯ã‚‰ãªã„ã§ãã ã•ã„ã€‚"
    
    # æœ€æ–°ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’å±¥æ­´ã«è¿½åŠ  (Gemini APIã«æ¸¡ã™ãŸã‚ã®messagesãƒªã‚¹ãƒˆã‚’ä½œæˆ)
    messages_to_send = []
    for item in conversation_history + [{"role": "user", "content": prompt_text}]:
        messages_to_send.append(
            Content(
                role=item["role"] if item["role"] != "assistant" else "model",
                parts=[Part(text=item["content"])]
            )
        )

    try:
        response_stream = await asyncio.to_thread(
            gemini_client.models.generate_content_stream,
            model="gemini-2.5-flash",
            contents=messages_to_send, # å±¥æ­´ã¨æœ€æ–°ã®å…¥åŠ›ã‚’æ¸¡ã™
            config=genai.types.GenerateContentConfig(
                system_instruction=system_instruction
            )
        )

        full_response = ""
        for chunk in response_stream:
            content = chunk.text
            if content:
                yield content 
                full_response += content
                
        # å¿œç­”ã‚’ã‚°ãƒ­ãƒ¼ãƒãƒ«ãªå±¥æ­´ã«è¿½åŠ  (ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—ã§å‚ç…§ã•ã‚Œã‚‹)
        conversation_history.append({"role": "user", "content": prompt_text})
        conversation_history.append({"role": "assistant", "content": full_response})
        
        print("âœ… Gemini: å…¨ã¦ã®å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚")
        
        # å±¥æ­´ãŒé•·ããªã‚Šã™ããŸã‚‰å¤ã„ã‚‚ã®ã‚’å‰Šé™¤ (ãƒˆãƒ¼ã‚¯ãƒ³ã‚³ã‚¹ãƒˆå‰Šæ¸›ã®ãŸã‚)
        # ä¾‹: å±¥æ­´ã‚’ç›´è¿‘ã®10ã‚¿ãƒ¼ãƒ³åˆ†ã«åˆ¶é™
        if len(conversation_history) > 10:
            conversation_history[:] = conversation_history[-10:]

    except Exception as e:
        print(f"âŒ Gemini APIã‚¨ãƒ©ãƒ¼: {e}")
        yield "APIæ¥ç¶šã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚æ™‚é–“ã‚’ç½®ã„ã¦å†åº¦ãŠè©±ã—ãã ã•ã„ã€‚"

# ====================================================================
# III. éŸ³å£°å‡ºåŠ› (TTS: VOICEVOX) - å¤‰æ›´ãªã—
# ====================================================================

async def generate_and_play_tts(text_stream):
    # ... (VOICEVOXã®ã‚³ãƒ¼ãƒ‰ã¯ã€gpt_tts_pipeline.pyã‹ã‚‰å¤‰æ›´ãªãã“ã“ã«è²¼ã‚Šä»˜ã‘ã¾ã™) ...
    full_text = ""
    sentence_buffer = "" 
    
    play_stream = sd.OutputStream(samplerate=RATE, channels=CHANNELS, dtype='float32')
    play_stream.start()
    
    print("ğŸ”ˆ VOICEVOX: åˆæˆãƒ»å†ç”Ÿã‚’é–‹å§‹ã—ã¾ã™...")

    async for chunk in text_stream:
        full_text += chunk
        sentence_buffer += chunk
        
        if any(p in sentence_buffer for p in ['ã€‚', 'ï¼', 'ï¼Ÿ', '\n']):
            audio_data = await _call_voicevox_api(sentence_buffer)
            
            if audio_data is not None:
                audio_data_float = np.frombuffer(audio_data, dtype=np.int16).astype(np.float32) / 32768.0
                play_stream.write(audio_data_float)
            
            sentence_buffer = "" 

    if sentence_buffer.strip():
        audio_data = await _call_voicevox_api(sentence_buffer)
        if audio_data is not None:
            audio_data_float = np.frombuffer(audio_data, dtype=np.int16).astype(np.float32) / 32768.0
            play_stream.write(audio_data_float)

    play_stream.stop()
    play_stream.close()
    print("âœ… VOICEVOX: å†ç”Ÿå®Œäº†ã€‚")
    return full_text


async def _call_voicevox_api(text):
    """VOICEVOXã®APIã‚’å‘¼ã³å‡ºã—ã¦éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹å†…éƒ¨é–¢æ•°"""
    if not text or not text.strip():
        return None
        
    try:
        # 1. éŸ³ç´ ã¨ã‚¢ã‚¯ã‚»ãƒ³ãƒˆã®å–å¾— (Audio Query)
        encoded_text = urllib.parse.quote(text) 
        response = await asyncio.to_thread(
            requests.post,
            f"{VOICEVOX_ENGINE_URL}/audio_query?speaker={VOICEVOX_SPEAKER_ID}&text={encoded_text}"
        )
        response.raise_for_status() 
        
        # 2. éŸ³å£°åˆæˆ (Synthesis)
        query = response.json()
        query['speedScale'] = VOICEVOX_SPEED_SCALE
        #query['pitchScale'] = VOICEVOX_PITCH_SCALE
        query['outputSamplingRate'] = RATE
        response_audio = await asyncio.to_thread(
            requests.post,
            f"{VOICEVOX_ENGINE_URL}/synthesis",
            params={'speaker': VOICEVOX_SPEAKER_ID},
            json=query
        )
        response_audio.raise_for_status()
        
        return response_audio.content 
        
    except requests.exceptions.RequestException as e:
        print(f"âŒ VOICEVOX APIã‚¨ãƒ©ãƒ¼: {e} (ãƒ†ã‚­ã‚¹ãƒˆ: \"{text}\")")
        return None